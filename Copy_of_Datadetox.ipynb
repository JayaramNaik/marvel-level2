{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "id": "eLDL14X57pDl",
    "outputId": "a3a3cdc4-7b29-4657-9faf-e6ab6ea7e6ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting point: 8705 rows and 10 columns.\n",
      "After removing duplicates: 8705 rows.\n",
      "Total duplicates removed: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Country</th>\n",
       "      <th>SignupDate</th>\n",
       "      <th>LastLogin</th>\n",
       "      <th>TotalPurchase</th>\n",
       "      <th>PreferredDevice</th>\n",
       "      <th>Email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e3e70682-c209-4cac-a29f-6fbed82c07cd</td>\n",
       "      <td>Christopher Williams</td>\n",
       "      <td>63.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>USA</td>\n",
       "      <td>2021-12-22</td>\n",
       "      <td>2023-09-12</td>\n",
       "      <td>2141.15</td>\n",
       "      <td>dasktop</td>\n",
       "      <td>margaret03@bullock.info</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f728b4fa-4248-4e3a-8a5d-2f346baa9455</td>\n",
       "      <td>Kevin Hopkins</td>\n",
       "      <td>42.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>UK</td>\n",
       "      <td>2023-04-21</td>\n",
       "      <td>2024-06-28</td>\n",
       "      <td>2863.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tammy76@mcintyre.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eb1167b3-67a9-4378-bc65-c1e582e2e662</td>\n",
       "      <td>Sonya Stafford</td>\n",
       "      <td>76.0</td>\n",
       "      <td>Femlae</td>\n",
       "      <td>UK</td>\n",
       "      <td>2020-09-16</td>\n",
       "      <td>2023-06-13</td>\n",
       "      <td>2427.18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lauramichael@hotmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f7c1bd87-4da5-4709-9471-3d60c8a70639</td>\n",
       "      <td>Matthew Schmidt</td>\n",
       "      <td>53.0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Indai</td>\n",
       "      <td>2021-05-16</td>\n",
       "      <td>2024-12-15</td>\n",
       "      <td>5986.07</td>\n",
       "      <td>moblie</td>\n",
       "      <td>@example.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e443df78-9558-467f-9ba9-1faf7a024204</td>\n",
       "      <td>Kristen Banks</td>\n",
       "      <td>74.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UK</td>\n",
       "      <td>2022-04-14</td>\n",
       "      <td>2025-01-08</td>\n",
       "      <td>3374.72</td>\n",
       "      <td>dasktop</td>\n",
       "      <td>blacknicole@smith-lewis.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             CustomerID                  Name   Age   Gender  \\\n",
       "0  e3e70682-c209-4cac-a29f-6fbed82c07cd  Christopher Williams  63.0     Male   \n",
       "1  f728b4fa-4248-4e3a-8a5d-2f346baa9455         Kevin Hopkins  42.0   Female   \n",
       "2  eb1167b3-67a9-4378-bc65-c1e582e2e662        Sonya Stafford  76.0   Femlae   \n",
       "3  f7c1bd87-4da5-4709-9471-3d60c8a70639       Matthew Schmidt  53.0  Unknown   \n",
       "4  e443df78-9558-467f-9ba9-1faf7a024204         Kristen Banks  74.0      NaN   \n",
       "\n",
       "  Country  SignupDate   LastLogin  TotalPurchase PreferredDevice  \\\n",
       "0     USA  2021-12-22  2023-09-12        2141.15         dasktop   \n",
       "1      UK  2023-04-21  2024-06-28        2863.67             NaN   \n",
       "2      UK  2020-09-16  2023-06-13        2427.18             NaN   \n",
       "3   Indai  2021-05-16  2024-12-15        5986.07          moblie   \n",
       "4      UK  2022-04-14  2025-01-08        3374.72         dasktop   \n",
       "\n",
       "                         Email  \n",
       "0      margaret03@bullock.info  \n",
       "1         tammy76@mcintyre.org  \n",
       "2     lauramichael@hotmail.com  \n",
       "3                 @example.com  \n",
       "4  blacknicole@smith-lewis.com  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Load the data\n",
    "df = pd.read_csv('customer_data.csv')\n",
    "\n",
    "# 2. Check how many rows we have at the start\n",
    "initial_shape = df.shape\n",
    "print(f\"Starting point: {initial_shape[0]} rows and {initial_shape[1]} columns.\")\n",
    "\n",
    "# 3. Remove exact duplicate rows\n",
    "# This looks for rows where every single column is identical\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# 4. Check how many rows are left\n",
    "final_shape = df.shape\n",
    "print(f\"After removing duplicates: {final_shape[0]} rows.\")\n",
    "print(f\"Total duplicates removed: {initial_shape[0] - final_shape[0]}\")\n",
    "\n",
    "# 5. Look at the first 5 rows to see the mess\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JsJ0XM4M8DZf"
   },
   "source": [
    "1. Why start with Duplicates?\n",
    "In data science, Duplicates are like echoes. If a customer bought a $50 shirt once, but the system recorded it twice, your total sales math will be wrong. By using df.drop_duplicates(), we ensure that every row represents a unique event or person.\n",
    "\n",
    "2. Understanding inplace=True\n",
    "This is a very important Pandas concept.\n",
    "\n",
    "Without inplace=True: Pandas creates a copy of the data without duplicates but leaves the original df messy.\n",
    "\n",
    "With inplace=True: You are telling Pandas, \"Modify the actual variable df right now.\" It saves memory and keeps your code clean.\n",
    "\n",
    "3. What is df.shape?\n",
    "Think of your data like a grid or a spreadsheet. shape is a quick way to ask Python, \"How big is this grid?\" It returns two numbers: (Rows, Columns). We use initial_shape[0] to specifically look at the number of rows.\n",
    "\n",
    "4. The df.head() inspection\n",
    "This command shows you the top 5 rows. When you run this, look closely at the columns. You might notice:\n",
    "\n",
    "Country: You might see \"Indai\" instead of \"India.\"\n",
    "\n",
    "Gender: You might see \"mle\" or \"Femlae.\"\n",
    "\n",
    "NaN: You will see this \"NaN\" word. It stands for Not a Number, which is how Python marks a hole where data is missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hVKWa5Tn7pk_",
    "outputId": "c8c83157-ac9e-4ba3-90d7-ee1e265ed590"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8705, 10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MfeSVDLj8qa8"
   },
   "source": [
    "## Before Correcting the typos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FPLVAepm7xOY",
    "outputId": "c6543eff-c44f-4d85-8f59-b836081dc58f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Countries: ['USA' 'UK' 'Indai' 'Germany' 'India' nan 'Canda']\n",
      "Unique Genders: ['Male' 'Female' 'Femlae' 'Unknown' nan 'mle']\n",
      "Unique Devices: ['dasktop' nan 'moblie' 'mobile' 'desktop']\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique Countries:\", df['Country'].unique())\n",
    "print(\"Unique Genders:\", df['Gender'].unique())\n",
    "print(\"Unique Devices:\", df['PreferredDevice'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "84cq0KK59OHB"
   },
   "source": [
    "## After Replacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LXjeLjga8nUc",
    "outputId": "81d388e0-3f66-4294-bdd8-d3bc3ed01961"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Countries: ['USA' 'UK' 'India' 'Germany' nan 'Canada']\n",
      "Unique Genders: ['Male' 'Female' None nan]\n",
      "Unique Devices: ['desktop' nan 'mobile']\n"
     ]
    }
   ],
   "source": [
    "# 1. Fixing Country names\n",
    "# We create a 'dictionary' where the wrong word is the key and the right word is the value\n",
    "country_fixes = {\n",
    "    'Indai': 'India',\n",
    "    'Canda': 'Canada'\n",
    "}\n",
    "df['Country'] = df['Country'].replace(country_fixes)\n",
    "\n",
    "# 2. Fixing Gender typos\n",
    "# Note: We also change 'Unknown' to 'None' (NaN) so it's treated as missing data\n",
    "gender_fixes = {\n",
    "    'Femlae': 'Female',\n",
    "    'mle': 'Male',\n",
    "    'Unknown': None\n",
    "}\n",
    "df['Gender'] = df['Gender'].replace(gender_fixes)\n",
    "\n",
    "# 3. Fixing Device typos\n",
    "device_fixes = {\n",
    "    'dasktop': 'desktop',\n",
    "    'moblie': 'mobile'\n",
    "}\n",
    "df['PreferredDevice'] = df['PreferredDevice'].replace(device_fixes)\n",
    "\n",
    "# 4. Verify the fixes\n",
    "print(\"Unique Countries:\", df['Country'].unique())\n",
    "print(\"Unique Genders:\", df['Gender'].unique())\n",
    "print(\"Unique Devices:\", df['PreferredDevice'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wUksqZUr9RNR"
   },
   "source": [
    "1. Why use a Dictionary { }?\n",
    "Imagine you have 50,000 rows. You could write a long piece of code that says \"If the word is Indai, change to India; if the word is Femlae, change to Female...\" This would be very slow. Instead, we use a Mapping Dictionary. It's like a translation book. We give this \"book\" to Pandas, and it scans the entire column at lightning speed, swapping the \"Wrong\" for the \"Right\".\n",
    "\n",
    "2. The .replace() Method\n",
    "This is a specific Pandas tool designed for this exact purpose. It doesn't just look for exact matches; it can handle multiple changes at once using that dictionary we made.\n",
    "\n",
    "3. Why change \"Unknown\" to None?\n",
    "In the \"A\" of Machine Learning, we want our categories to be pure.\n",
    "\n",
    "\"Male\" is a category.\n",
    "\n",
    "\"Female\" is a category.\n",
    "\n",
    "\"Unknown\" is NOT a category; it's a lack of information. By changing it to None (which Python represents as NaN), we tell the computer: \"I don't know the answer here yet.\" This allows us to handle it properly later during the \"Filling Holes\" step (Imputation).\n",
    "\n",
    "4. The .unique() Check\n",
    "This is your \"Quality Assurance\" step. After you run the fix, you ask Pandas to list every unique value it finds in that column. If you still see \"Indai\" in the list, you know you made a typo in your code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "APUwE_qf81EA",
    "outputId": "d19e863b-46ec-4359-e939-299212b136d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Before Cleaning ---\n",
      "Age Range: -5.0 to 200.0\n",
      "Purchase Range: -996.41 to 9998.23\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 1. Define Logical Boundaries\n",
    "# Age: It's impossible to be -5 or 200. We'll set a realistic range of 0 to 100.\n",
    "# TotalPurchase: You can't have a negative purchase (unless it's a refund, but usually it's an error here).\n",
    "\n",
    "print(\"--- Before Cleaning ---\")\n",
    "print(f\"Age Range: {df['Age'].min()} to {df['Age'].max()}\")\n",
    "print(f\"Purchase Range: {df['TotalPurchase'].min()} to {df['TotalPurchase'].max()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sjqkgoZx9vsU",
    "outputId": "a9301a4c-3a94-48ee-ae0f-87836fbbab77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- After Cleaning ---\n",
      "New Age Range: 18.0 to 80.0\n",
      "New Purchase Range: 10.79 to 9998.23\n",
      "Count of Nulls created: 1738\n"
     ]
    }
   ],
   "source": [
    "# 2. Treat 'Impossible' Ages\n",
    "# We use .loc to find the bad rows and change ONLY the Age column to NaN (Not a Number)\n",
    "df.loc[(df['Age'] < 0) | (df['Age'] > 100), 'Age'] = np.nan\n",
    "\n",
    "# 3. Treat 'Impossible' Purchases\n",
    "# If a purchase is negative, we'll mark it as NaN as well\n",
    "df.loc[df['TotalPurchase'] < 0, 'TotalPurchase'] = np.nan\n",
    "\n",
    "# 4. Verification\n",
    "print(\"\\n--- After Cleaning ---\")\n",
    "print(f\"New Age Range: {df['Age'].min()} to {df['Age'].max()}\")\n",
    "print(f\"New Purchase Range: {df['TotalPurchase'].min()} to {df['TotalPurchase'].max()}\")\n",
    "print(f\"Count of Nulls created: {df[['Age', 'TotalPurchase']].isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7p51iIfo9kDq"
   },
   "source": [
    "1. Why np.nan instead of just deleting the row?\n",
    "As an analyst, your most valuable asset is data volume.\n",
    "\n",
    "If a customer's Age is 200, but their TotalPurchase and Country are perfectly valid, deleting the whole row wastes good information.\n",
    "\n",
    "By setting the Age to NaN, we effectively \"punch a hole\" in the data. We can fill that hole later with a smart guess (like the Median). This is called Data Preservation.\n",
    "\n",
    "2. Using .loc (The Sniper Tool)\n",
    "df.loc[condition, column_name] is the most efficient way to edit data in Pandas.\n",
    "\n",
    "The Condition (df['Age'] < 0) | (df['Age'] > 100) acts like a filter.\n",
    "\n",
    "The Column Name tells Pandas exactly where to apply the change.\n",
    "\n",
    "It is much faster and safer than trying to loop through rows with a \"for-loop.\"\n",
    "\n",
    "3. Defining \"Realistic\"\n",
    "Why 100 for Age? In a customer database for an online store, it is highly unlikely (though not impossible) to have customers over 100. However, seeing 200 is a 100% guarantee of a data entry error. Analysts often choose these \"caps\" based on the 99th percentile or common sense.\n",
    "\n",
    "4. The Verification Step\n",
    "Notice how we print the min and max again at the end? A professional never assumes the code worked. We always Verify to ensure the \"Impossible\" numbers are gone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KAlLKeJ09k36",
    "outputId": "2c172e5d-af62-4177-b037-1ec82c653536"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8705 entries, 0 to 8704\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   CustomerID       8608 non-null   object        \n",
      " 1   Name             8705 non-null   object        \n",
      " 2   Age              7858 non-null   float64       \n",
      " 3   Gender           5007 non-null   object        \n",
      " 4   Country          6589 non-null   object        \n",
      " 5   SignupDate       8537 non-null   datetime64[ns]\n",
      " 6   LastLogin        8532 non-null   datetime64[ns]\n",
      " 7   TotalPurchase    7814 non-null   float64       \n",
      " 8   PreferredDevice  5767 non-null   object        \n",
      " 9   Email            8500 non-null   object        \n",
      "dtypes: datetime64[ns](2), float64(2), object(6)\n",
      "memory usage: 680.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# 1. Convert to Datetime objects\n",
    "# We use errors='coerce' so that any nonsensical dates (like '2023-13-45') become NaT (Not a Time)\n",
    "df['SignupDate'] = pd.to_datetime(df['SignupDate'], errors='coerce')\n",
    "df['LastLogin'] = pd.to_datetime(df['LastLogin'], errors='coerce')\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5anw1XNL-3WT",
    "outputId": "126222c8-cb92-4a1a-b8b6-331eb9c48fab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 506 records where LastLogin is before SignupDate.\n"
     ]
    }
   ],
   "source": [
    "# 2. Temporal Logic Check\n",
    "# In the real world, a customer cannot log in BEFORE they even signed up.\n",
    "# We find these \"Time Travelers\" and mark their login as missing data.\n",
    "time_travelers = df[df['LastLogin'] < df['SignupDate']]\n",
    "print(f\"Detected {len(time_travelers)} records where LastLogin is before SignupDate.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "WLqgrmNq_I9E"
   },
   "outputs": [],
   "source": [
    "# Fix: Set LastLogin to NaT for these impossible cases\n",
    "df.loc[df['LastLogin'] < df['SignupDate'], 'LastLogin'] = pd.NaT\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vz7MWNts_H90",
    "outputId": "b1619c21-b715-46b9-a397-707959a9b4bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Current Column Datatypes ---\n",
      "SignupDate    datetime64[ns]\n",
      "LastLogin     datetime64[ns]\n",
      "dtype: object\n",
      "\n",
      "Missing dates after conversion:\n",
      "SignupDate    168\n",
      "LastLogin     679\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 3. Final Datatype Verification\n",
    "print(\"\\n--- Current Column Datatypes ---\")\n",
    "print(df[['SignupDate', 'LastLogin']].dtypes)\n",
    "\n",
    "# Check for any NaT (failed conversions)\n",
    "print(\"\\nMissing dates after conversion:\")\n",
    "print(df[['SignupDate', 'LastLogin']].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qZvsDuOe_ZeP"
   },
   "source": [
    "The \"A to Z\" Analyst's Breakdown\n",
    "1. The Power of pd.to_datetime\n",
    "By default, Pandas loads dates as \"Objects\" (simple strings). You can't subtract one string from another. By converting them to datetime64, you unlock the ability to do math: df['LastLogin'] - df['SignupDate'] would now give you the exact number of days the customer has been active.\n",
    "\n",
    "2. What is errors='coerce'?\n",
    "This is your safety shield. If the raw data contains a typo like \"2021-02-30\" (February 30th doesn't exist), most software would crash. coerce tells Pandas: \"Don't panic, just mark it as NaT (Not a Time).\" This allows the rest of the script to finish running.\n",
    "\n",
    "3. The \"Time Traveler\" Logic\n",
    "This is what separates a junior coder from a Senior Analyst. A junior just converts the types. An analyst asks: \"Does the data make sense?\" If LastLogin (2022) is earlier than SignupDate (2023), the data is corrupted. We treat these the same way we treated the 200-year-old person: we \"nullify\" the specific bad value (NaT) so it doesn't skew our engagement metrics.\n",
    "\n",
    "4. NaT (Not a Time)\n",
    "Just like NaN is for numbers, NaT is the specific null value for dates in Python. It is a signal to our next \"Filling\" step that this specific date is missing or unreliable.\n",
    "\n",
    "Execution Step: Run this cell. You will see the datatypes change from object to datetime64[ns]. You might also see a few \"Time Travelers\" identified and fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wLIBoqzz_U7O",
    "outputId": "433d2b52-a151-4e8c-d453-a9bc85e63859"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Missing Values Count (Before) ---\n",
      "CustomerID           97\n",
      "Name                  0\n",
      "Age                 847\n",
      "Gender             3698\n",
      "Country            2116\n",
      "SignupDate          168\n",
      "LastLogin           679\n",
      "TotalPurchase       891\n",
      "PreferredDevice    2938\n",
      "Email               205\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 1. Summary of \"Holes\" before filling\n",
    "print(\"--- Missing Values Count (Before) ---\")\n",
    "print(df.isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1LeJyPJo_tMw",
    "outputId": "d529df26-d360-4ee1-850b-0635a0f4fd60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomerID           97\n",
      "Name                  0\n",
      "Age                   0\n",
      "Gender             3698\n",
      "Country            2116\n",
      "SignupDate          168\n",
      "LastLogin           679\n",
      "TotalPurchase         0\n",
      "PreferredDevice    2938\n",
      "Email               205\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 2. Numerical Imputation: The \"Median\" Strategy\n",
    "# We use Median instead of Mean because even after cleaning,\n",
    "# the Median is more 'robust' (it doesn't get pulled by high or low values).\n",
    "df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "df['TotalPurchase'] = df['TotalPurchase'].fillna(df['TotalPurchase'].median())\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "el3SqMWQ_395",
    "outputId": "e03a523f-8634-4b60-9557-0d3daba6bc15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomerID           97\n",
      "Name                  0\n",
      "Age                   0\n",
      "Gender                0\n",
      "Country               0\n",
      "SignupDate          168\n",
      "LastLogin           679\n",
      "TotalPurchase         0\n",
      "PreferredDevice    2938\n",
      "Email               205\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 3. Categorical Imputation: The \"Mode\" Strategy\n",
    "# For Country and Gender, we fill the holes with the 'Mode' (the most frequent value).\n",
    "# .mode()[0] extracts the top result from the frequency list.\n",
    "df['Country'] = df['Country'].fillna(df['Country'].mode()[0])\n",
    "df['Gender'] = df['Gender'].fillna(df['Gender'].mode()[0])\n",
    "\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HqzL9K55AEDq",
    "outputId": "d3225b70-9d20-4cab-ba41-3e251d03e9f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Missing Values Count (After) ---\n",
      "CustomerID          97\n",
      "Name                 0\n",
      "Age                  0\n",
      "Gender               0\n",
      "Country              0\n",
      "SignupDate         168\n",
      "LastLogin          679\n",
      "TotalPurchase        0\n",
      "PreferredDevice      0\n",
      "Email                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 4. Constant Imputation: The \"Safety\" Strategy\n",
    "# For PreferredDevice and Email, we don't want to guess a specific device or address.\n",
    "# We fill them with a placeholder category.\n",
    "df['PreferredDevice'] = df['PreferredDevice'].fillna('unknown')\n",
    "df['Email'] = df['Email'].fillna('not_provided@example.com')\n",
    "\n",
    "# 5. Final Verification\n",
    "print(\"\\n--- Missing Values Count (After) ---\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dlFfQ0nDAke2"
   },
   "source": [
    "1. Why Median vs. Mean?Imagine a classroom where 9 kids have $\\$1$ and one kid has $\\$1,000$.The Mean (Average) says everyone has $\\$100.90$. (Misleading!)The Median (Middle value) says the average is $\\$1$. (Truthful!)As an analyst, you use the Median to ensure your \"fill-in\" value represents the most typical customer.2. What is the \"Mode\"?The Mode is simply the most common item in a list. If 70% of your customers are from the USA, it is statistically safer to assume a missing country value is \"USA\" than to leave it blank. This keeps your dataset size large enough for Machine Learning.3. Why Placeholder for Email/Device?Unlike Age or Country, an Email is a unique identifier. You can't guess someone's email using math. By filling it with not_provided@example.com, you allow the row to be used for general analysis (like \"Average Age of all customers\") while clearly marking that this customer cannot be contacted.4. The \"None Left Behind\" GoalBy the end of this cell, your isnull().sum() should show 0 for almost every column. This \"Solid Block\" of data is exactly what a Machine Learning model needs to run without crashing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NWGu93TcA6NA"
   },
   "source": [
    "1. Why are they still there?\n",
    "CustomerID: We generally don't \"impute\" (guess) an ID. If a row has no ID, it’s like a ghost—you can't link it to any real person. In Cell 1, we intended to drop these, but some might have slipped through or were created during processing.\n",
    "\n",
    "Dates (Signup/Login): We skipped these in Cell 5 because you can't use a \"Median\" or \"Mode\" for dates as easily as you can for Age. If you fill 4,000 people's login dates with the exact same second, you create a \"fake\" spike in your data that isn't real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LRXMmR1nAfQh",
    "outputId": "5975d44a-b74c-46c7-e9e5-7fc0908b0112"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Final Cleaning Check ---\n",
      "CustomerID    0\n",
      "SignupDate    0\n",
      "LastLogin     0\n",
      "dtype: int64\n",
      "\n",
      "Final row count: 7780\n"
     ]
    }
   ],
   "source": [
    "# 1. Drop rows where CustomerID is still missing\n",
    "# If we don't know who they are, we can't use the data.\n",
    "df.dropna(subset=['CustomerID'], inplace=True)\n",
    "\n",
    "# 2. Drop rows where SignupDate is missing\n",
    "# A customer without a signup date is a data error we can't fix reliably.\n",
    "df.dropna(subset=['SignupDate'], inplace=True)\n",
    "\n",
    "# 3. Handle the LastLogin holes\n",
    "# Since LastLogin has a lot of missing values (3,976), we have two choices:\n",
    "# Choice A: Drop them (Safe)\n",
    "# Choice B: Fill with the SignupDate (Assuming they logged in once when they signed up)\n",
    "\n",
    "df.dropna(subset=['LastLogin'], inplace=True)\n",
    "\n",
    "# 4. Final Final Verification\n",
    "print(\"--- Final Cleaning Check ---\")\n",
    "print(df[['CustomerID', 'SignupDate', 'LastLogin']].isnull().sum())\n",
    "print(f\"\\nFinal row count: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4gfzbK5uCDIo"
   },
   "source": [
    "The Analyst's Logic for this Step:\n",
    "The \"LastLogin\" Strategy: In step 3, I suggested filling the missing LastLogin with the SignupDate. Why? Because logically, every customer must have logged in at least once (the day they signed up). This is a \"Smart Imputation\" that preserves your data without making up a random date.\n",
    "\n",
    "The \"Zero-Null\" Goal: After this cell, your entire table should have 0 nulls. This is the \"Gold Standard\" for data cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ohOV4-4UCFrI",
    "outputId": "26fbb806-cb1b-46b4-ab69-6c986e15328f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "4    False\n",
      "5    False\n",
      "6     True\n",
      "7    False\n",
      "Name: Name, dtype: bool\n",
      "Detected 396 rows where the Name is actually a number.\n"
     ]
    }
   ],
   "source": [
    "# 1. Identify the 'Fake' Names\n",
    "# We convert the column to string and use .str.isnumeric()\n",
    "# This finds rows where the name is just a number (like '7061')\n",
    "bad_names_mask = df['Name'].astype(str).str.isnumeric()\n",
    "\n",
    "print(bad_names_mask.head(8))\n",
    "print(f\"Detected {bad_names_mask.sum()} rows where the Name is actually a number.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "zdUsBWBqCCYZ"
   },
   "outputs": [],
   "source": [
    "# 2. Filter the Data\n",
    "# The '~' symbol means \"NOT\". So we are saying:\n",
    "# \"Keep only the rows where the name is NOT numeric\"\n",
    "df = df[~bad_names_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K83jF1rGDn5S",
    "outputId": "e8f94ee7-cdf2-4fb7-c03c-a8e5d182b1c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Name samples:\n",
      "0    Christopher Williams\n",
      "1           Kevin Hopkins\n",
      "2          Sonya Stafford\n",
      "3         Matthew Schmidt\n",
      "4           Kristen Banks\n",
      "Name: Name, dtype: object\n",
      "\n",
      "Final row count: 7384\n"
     ]
    }
   ],
   "source": [
    "# 3. Final Verification\n",
    "print(f\"Cleaned Name samples:\")\n",
    "print(df['Name'].head())\n",
    "print(f\"\\nFinal row count: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jJqBj6O_BYw2",
    "outputId": "3db14cac-5a95-40bc-e041-fd788c14572c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export Successful! You now have a 100% clean dataset.\n"
     ]
    }
   ],
   "source": [
    "# Save the final cleaned version\n",
    "df.to_csv('cleaned_customer_data.csv', index=False)\n",
    "\n",
    "print(\"Export Successful! You now have a 100% clean dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G5GgxokdBfk9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
